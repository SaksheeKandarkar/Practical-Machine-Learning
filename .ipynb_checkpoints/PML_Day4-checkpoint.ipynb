{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37ce0f3b-83c9-4369-ba2f-69bc3e6ce732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a215a9-88ad-4bac-9859-628d86ef48b6",
   "metadata": {},
   "source": [
    "# Heart Disease Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22232732-5e0d-40a7-89ec-cad34d25856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:\\CDAC\\ML\\Topic 5\\cleaned_76hd.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dadca5b7-265a-4f25-8d2b-43f39baa94f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V18</th>\n",
       "      <th>...</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>V41</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V51</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.723618</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.244292</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.637037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.798995</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>0.404040</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.597990</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.235160</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.648241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.618519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.648241</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.208333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.214612</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.596296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.768844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242009</td>\n",
       "      <td>0.404040</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229630</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.604167</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.648241</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.348148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.345679</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.547739</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.477169</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.337037</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.648241</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V3  V4        V9       V10       V11       V12       V14       V15  \\\n",
       "0    0.708333   1  0.000000  0.723618  0.003953  0.244292  0.505051  0.370370   \n",
       "1    0.791667   1  0.023256  0.798995  0.003953  0.365297  0.404040  0.740741   \n",
       "2    0.791667   1  0.023256  0.597990  0.003953  0.235160  0.202020  0.648148   \n",
       "3    0.166667   1  0.015504  0.648241  0.000000  0.283105  0.000000  0.000000   \n",
       "4    0.250000   0  0.007752  0.648241  0.003953  0.178082  0.000000  0.000000   \n",
       "..        ...  ..       ...       ...       ...       ...       ...       ...   \n",
       "277  0.208333   0  0.015504  0.688442  0.003953  0.214612  0.202020  0.425926   \n",
       "278  0.583333   1  0.007752  0.768844  0.000000  0.242009  0.404040  0.648148   \n",
       "279  0.604167   0  0.023256  0.648241  0.003953  0.162100  0.000000  0.000000   \n",
       "280  0.583333   1  0.023256  0.547739  0.003953  0.477169  0.202020  0.277778   \n",
       "281  0.375000   1  0.015504  0.648241  0.003953  0.289954  0.000000  0.000000   \n",
       "\n",
       "     V16  V18  ...  V39       V40  V41       V43       V44   V51       V55  \\\n",
       "0      1    1  ...  0.0  0.370968  1.0  0.637037  0.000000  0.75  0.035714   \n",
       "1      0    1  ...  0.0  0.241935  0.5  0.685185  1.000000  0.00  0.035714   \n",
       "2      0    1  ...  0.0  0.419355  0.5  0.555556  0.666667  1.00  0.035714   \n",
       "3      0    1  ...  0.0  0.564516  1.0  0.618519  0.000000  0.00  0.035714   \n",
       "4      0    1  ...  0.0  0.225806  0.0  0.148148  0.000000  0.00  0.035714   \n",
       "..   ...  ...  ...  ...       ...  ...       ...       ...   ...       ...   \n",
       "277    0    0  ...  0.0  0.000000  0.5  0.596296  0.000000  0.00  0.142857   \n",
       "278    0    1  ...  0.0  0.000000  0.0  0.229630  0.333333  0.00  0.178571   \n",
       "279    0    1  ...  0.0  0.096774  0.5  0.348148  0.000000  0.00  0.071429   \n",
       "280    0    1  ...  0.0  0.483871  0.5  0.337037  0.333333  1.00  0.142857   \n",
       "281    0    1  ...  0.0  0.000000  0.0  0.203704  0.000000  0.00  0.142857   \n",
       "\n",
       "          V56       V57  V58  \n",
       "0    0.185185  0.964286    0  \n",
       "1    0.049383  0.964286    1  \n",
       "2    0.234568  0.964286    1  \n",
       "3    0.037037  0.964286    0  \n",
       "4    0.209877  0.964286    0  \n",
       "..        ...       ...  ...  \n",
       "277  0.098765  1.000000    0  \n",
       "278  0.049383  1.000000    1  \n",
       "279  0.345679  1.000000    0  \n",
       "280  0.037037  1.000000    1  \n",
       "281  0.283951  1.000000    0  \n",
       "\n",
       "[282 rows x 39 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dc7ebc6-5d42-4e89-a2f6-d8a5714c289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdf63bbb-490c-421b-b99e-ae594293555c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V58\n",
       "0    0.546099\n",
       "1    0.453901\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['V58'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9519a1-0025-49e0-957f-293fe8ceab6a",
   "metadata": {},
   "source": [
    "# Task : Detect Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b30cda00-881f-4a9f-b7a2-18d85a52b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and Y\n",
    "X=df.drop(['V58'],axis=1)\n",
    "Y=df['V58']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "792dcf8c-3a5b-4e63-bfc2-2760d7b269cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((282, 38), (282,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5b7623e-68ba-4148-b79d-5cbe18e0f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=7,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "542b360f-eabc-48b3-a2bb-be5f56d28b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((197, 38), (85, 38), (197,), (85,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,Y_train.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "800c4858-51b9-4da5-9465-47c9c7c76bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V58\n",
       "0    0.548223\n",
       "1    0.451777\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "909461f9-ae10-4ed2-be5b-fc34f7b759c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V58\n",
       "0    0.541176\n",
       "1    0.458824\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4765613-e346-4fc1-b8fd-7a53fab4289a",
   "metadata": {},
   "source": [
    "# Apply classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c080d2af-7e1b-438e-9371-50d83deac5b9",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4566a8b-6db4-425f-bbc8-79522a13e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28b3bf46-5117-4b9e-8b45-57a622862aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight='balanced',random_state=7)\n",
    "lr.fit(X_train,Y_train)\n",
    "Y_pred = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80db36e5-0f46-4986-a51e-833d7eb1a319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.79        46\n",
      "           1       0.74      0.79      0.77        39\n",
      "\n",
      "    accuracy                           0.78        85\n",
      "   macro avg       0.78      0.78      0.78        85\n",
      "weighted avg       0.78      0.78      0.78        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35b93c55-2350-4155-ac6b-3cb571cf5816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.79        46\n",
      "           1       0.74      0.79      0.77        39\n",
      "\n",
      "    accuracy                           0.78        85\n",
      "   macro avg       0.78      0.78      0.78        85\n",
      "weighted avg       0.78      0.78      0.78        85\n",
      "\n",
      "GaussianNB               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        46\n",
      "           1       1.00      0.36      0.53        39\n",
      "\n",
      "    accuracy                           0.71        85\n",
      "   macro avg       0.82      0.68      0.66        85\n",
      "weighted avg       0.81      0.71      0.67        85\n",
      "\n",
      "MultinomialNB               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81        46\n",
      "           1       0.78      0.79      0.78        39\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.80      0.80      0.80        85\n",
      "weighted avg       0.80      0.80      0.80        85\n",
      "\n",
      "BernoulliNB               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84        46\n",
      "           1       0.82      0.79      0.81        39\n",
      "\n",
      "    accuracy                           0.82        85\n",
      "   macro avg       0.82      0.82      0.82        85\n",
      "weighted avg       0.82      0.82      0.82        85\n",
      "\n",
      "SVC               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80        46\n",
      "           1       0.76      0.79      0.78        39\n",
      "\n",
      "    accuracy                           0.79        85\n",
      "   macro avg       0.79      0.79      0.79        85\n",
      "weighted avg       0.79      0.79      0.79        85\n",
      "\n",
      "KNeighborsClassifier               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76        46\n",
      "           1       0.74      0.64      0.68        39\n",
      "\n",
      "    accuracy                           0.73        85\n",
      "   macro avg       0.73      0.72      0.72        85\n",
      "weighted avg       0.73      0.73      0.73        85\n",
      "\n",
      "DecisionTreeClassifier               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73        46\n",
      "           1       0.67      0.74      0.71        39\n",
      "\n",
      "    accuracy                           0.72        85\n",
      "   macro avg       0.72      0.72      0.72        85\n",
      "weighted avg       0.72      0.72      0.72        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes=[LogisticRegression(class_weight='balanced',random_state=7),GaussianNB(),MultinomialNB(),BernoulliNB(),SVC(C=1.0,kernel='poly',degree =2,class_weight='balanced',random_state=9),KNeighborsClassifier(n_neighbors=4,weights='distance'),DecisionTreeClassifier(criterion='gini',random_state=7)]\n",
    "for obj in classes:\n",
    "    obj.fit(X_train,Y_train)\n",
    "    Y_pred=obj.predict(X_test)\n",
    "    print(type(obj).__name__,classification_report(Y_test,Y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd89c052-739e-476f-8e5a-1b496f801238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm._classes:\n",
      "\n",
      "class SVC(sklearn.svm._base.BaseSVC)\n",
      " |  SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`~sklearn.svm.LinearSVC` or\n",
      " |  :class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`~sklearn.kernel_approximation.Nystroem` transformer or\n",
      " |  other :ref:`kernel_approximation`.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  To learn how to tune SVC's hyperparameters, see the following example:\n",
      " |  :ref:`sphx_glr_auto_examples_model_selection_plot_nested_cross_validation_iris.py`\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive. The penalty\n",
      " |      is a squared l2 penalty. For an intuitive visualization of the effects\n",
      " |      of scaling the regularization parameter C, see\n",
      " |      :ref:`sphx_glr_auto_examples_svm_plot_svm_scale_c.py`.\n",
      " |  \n",
      " |  kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} or callable,          default='rbf'\n",
      " |      Specifies the kernel type to be used in the algorithm. If\n",
      " |      none is given, 'rbf' will be used. If a callable is given it is used to\n",
      " |      pre-compute the kernel matrix from data matrices; that matrix should be\n",
      " |      an array of shape ``(n_samples, n_samples)``. For an intuitive\n",
      " |      visualization of different kernel types see\n",
      " |      :ref:`sphx_glr_auto_examples_svm_plot_svm_kernels.py`.\n",
      " |  \n",
      " |  degree : int, default=3\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Must be non-negative. Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, default='scale'\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features\n",
      " |      - if float, must be non-negative.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, default=0.0\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : bool, default=True\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |      See the :ref:`User Guide <shrinking_svm>`.\n",
      " |  \n",
      " |  probability : bool, default=False\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, will slow down that method as it internally uses\n",
      " |      5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      " |      `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, default=200\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, default=-1\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, note that\n",
      " |      internally, one-vs-one ('ovo') is always used as a multi-class strategy\n",
      " |      to train models; an ovr matrix is only constructed from the ovo matrix.\n",
      " |      The parameter is ignored for binary classification.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  break_ties : bool, default=False\n",
      " |      If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      " |      :term:`predict` will break ties according to the confidence values of\n",
      " |      :term:`decision_function`; otherwise the first class among the tied\n",
      " |      classes is returned. Please note that breaking ties comes at a\n",
      " |      relatively high computational cost compared to a simple predict.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the pseudo random number generation for shuffling the data for\n",
      " |      probability estimates. Ignored when `probability` is False.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_weight_ : ndarray of shape (n_classes,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (n_classes * (n_classes - 1) / 2, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  dual_coef_ : ndarray of shape (n_classes -1, n_SV)\n",
      " |      Dual coefficients of the support vector in the decision\n",
      " |      function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
      " |      their targets.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the :ref:`multi-class section of the User Guide\n",
      " |      <svm_multi_class>` for details.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_iter_ : ndarray of shape (n_classes * (n_classes - 1) // 2,)\n",
      " |      Number of iterations run by the optimization routine to fit the model.\n",
      " |      The shape of this attribute depends on the number of models optimized\n",
      " |      which in turn depends on the number of classes.\n",
      " |  \n",
      " |      .. versionadded:: 1.1\n",
      " |  \n",
      " |  support_ : ndarray of shape (n_SV)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      " |      Support vectors. An empty array if kernel is precomputed.\n",
      " |  \n",
      " |  n_support_ : ndarray of shape (n_classes,), dtype=int32\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  probA_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |  probB_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |      If `probability=True`, it corresponds to the parameters learned in\n",
      " |      Platt scaling to produce probability estimates from decision values.\n",
      " |      If `probability=False`, it's an empty array. Platt scaling uses the\n",
      " |      logistic function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SVR : Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC : Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See Also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic Outputs for Support Vector\n",
      " |      Machines and Comparisons to Regularized Likelihood Methods\"\n",
      " |      <https://citeseerx.ist.psu.edu/doc_view/pid/42e5ed832d4310ce4378c44d05570439df28a393>`_\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('svc', SVC(gamma='auto'))])\n",
      " |  \n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm._base.BaseSVC\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.svm._classes.SVC, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.svm._classes.SVC from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.svm._classes.SVC, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.svm._classes.SVC from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluate the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : ndarray of shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model needs to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  probA_\n",
      " |      Parameter learned in Platt scaling when `probability=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape  (n_classes * (n_classes - 1) / 2)\n",
      " |  \n",
      " |  probB_\n",
      " |      Parameter learned in Platt scaling when `probability=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape  (n_classes * (n_classes - 1) / 2)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  unused_param = 'nu'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)                 or (n_samples, n_samples)\n",
      " |          Training vectors, where `n_samples` is the number of samples\n",
      " |          and `n_features` is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |      Weights assigned to the features when `kernel=\"linear\"`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape (n_features, n_classes)\n",
      " |  \n",
      " |  n_support_\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs)\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ee8ae-417c-41a6-be2c-8293f391f849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
